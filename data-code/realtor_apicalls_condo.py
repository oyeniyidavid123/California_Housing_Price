# -*- coding: utf-8 -*-
"""Realtor_API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mSo-2a2_3OHDLb5Fh0MjldUJIFmagQMD
"""

import requests

url = "https://realtor.p.rapidapi.com/properties/v2/list-for-sale"

querystring = {"sort":"relevance","prop_type":"condo","city":"Oakland","limit":"200","offset":"0","state_code":"CA","radius":"50"}

headers = {
    'x-rapidapi-host': "realtor.p.rapidapi.com",
    'x-rapidapi-key': "520f14fa3cmshe49651674a1d7cfp1a9ee8jsne02bb6c7f697"
    }

response_condo = requests.request("GET", url, headers=headers, params=querystring)
condo_json = response_condo.json()

condo_property = condo_json['properties']

condo_property[1].keys()

import pandas as pd
condo_listing=pd.DataFrame(condo_property)
len(condo_listing)

condo_listing['prop_type'].value_counts()

from pandas.io.json import json_normalize
condo_address = json_normalize(condo_listing['address'])
condo_address['county'].value_counts()

condo__df=pd.concat([condo_listing[['property_id', 'prop_type', 'price', 'baths_half', 'baths_full', 'beds', 'building_size']],condo_address[['city', 'postal_code', 'state_code','county']]],axis=1)
condo__df.dropna(subset=['building_size'], inplace=True)
condo__df

condo__df.fillna(0,inplace=True)
condo__df.reset_index(inplace=True)

del condo__df['index']

condo__df

building_size = json_normalize(condo__df['building_size'])
building_size

clean_condo=pd.concat([condo__df,building_size['size']],axis=1)
clean_condo.drop(columns='building_size',inplace=True)
clean_condo.rename(columns={'size':'building_size'},inplace=True)
clean_condo

clean_condo.head()

from google.colab import drive

clean_condo.to_csv('/drive/My Drive/Project_3/Oakland50_condo.csv')

import requests

url = "https://realtor.p.rapidapi.com/properties/v2/list-for-sale"

querystring = {"sort":"relevance","prop_type":"single_family","city":"Sacramento","limit":"200","offset":"0","state_code":"CA","radius":"20"}

headers = {
    'x-rapidapi-host': "realtor.p.rapidapi.com",
    'x-rapidapi-key': "520f14fa3cmshe49651674a1d7cfp1a9ee8jsne02bb6c7f697"
    }

response_single = requests.request("GET", url, headers=headers, params=querystring)
single_json = response_single.json()

single_properties = single_json['properties']

import pandas as pd
singlefam_listing=pd.DataFrame(single_properties)
len(singlefam_listing)

from pandas.io.json import json_normalize
singlefam_address = json_normalize(singlefam_listing['address'])
singlefam_address['county'].value_counts()

single_fam_df=pd.concat([singlefam_listing[['property_id', 'prop_type', 'price', 'baths_half', 'baths_full', 'beds', 'building_size','lot_size']],singlefam_address[['city', 'postal_code', 'state_code','county']]],axis=1)
single_fam_df.dropna(subset=['building_size','lot_size'], inplace=True)
single_fam_df

single_fam_df.fillna(0,inplace=True)
single_fam_df.reset_index(inplace=True)

single_fam_df

building_size = json_normalize(single_fam_df['building_size'])
lot_size=json_normalize(single_fam_df['lot_size'])
clean_single_df=pd.concat([single_fam_df,building_size['size']],axis=1)
clean_single_df.drop(columns='building_size',inplace=True)
clean_single_df.rename(columns={'size':'building_size'},inplace=True)
clean_single_df

singlefam_df=pd.concat([clean_single_df,lot_size['size']],axis=1)
singlefam_df.drop(columns='lot_size',inplace=True)
singlefam_df.rename(columns={'size':'lot_size'},inplace=True)

singlefam_df

from google.colab import drive

singlefam_df.to_csv('/drive/My Drive/Project_3/sacramento_single_family.csv')

!pip install -q matplotlib-venn

# To determine which version you're using:
!pip show tensorflow

# For the current version: 
!pip install --upgrade tensorflow

!pip install tf-nightly

pip install pycaret

from pycaret import enable_colab 
enable_colab()



