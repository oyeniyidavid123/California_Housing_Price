# -*- coding: utf-8 -*-
"""Realtor_API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mSo-2a2_3OHDLb5Fh0MjldUJIFmagQMD
"""

import requests

url = "https://realtor.p.rapidapi.com/properties/v2/list-for-sale"

querystring = {"sort":"relevance","prop_type":"condo","city":"Oakland","limit":"200","offset":"0","state_code":"CA","radius":"50"}

headers = {
    'x-rapidapi-host': "realtor.p.rapidapi.com",
    'x-rapidapi-key': "520f14fa3cmshe49651674a1d7cfp1a9ee8jsne02bb6c7f697"
    }

response_condo = requests.request("GET", url, headers=headers, params=querystring)
condo_json = response_condo.json()



condo_property = condo_json['properties']

condo_property[1].keys()

import pandas as pd
condo_listing=pd.DataFrame(condo_property)
len(condo_listing)

condo_listing['prop_type'].value_counts()

from pandas.io.json import json_normalize
condo_address = json_normalize(condo_listing['address'])
condo_address['county'].value_counts()

condo__df=pd.concat([condo_listing[['property_id', 'prop_type', 'price', 'baths_half', 'baths_full', 'beds', 'building_size']],condo_address[['city', 'postal_code', 'state_code','county']]],axis=1)
condo__df.dropna(subset=['building_size'], inplace=True)
condo__df

condo__df.fillna(0,inplace=True)
condo__df.reset_index(inplace=True)

del condo__df['index']

condo__df

building_size = json_normalize(condo__df['building_size'])
building_size

clean_condo=pd.concat([condo__df,building_size['size']],axis=1)
clean_condo.drop(columns='building_size',inplace=True)
clean_condo.rename(columns={'size':'building_size'},inplace=True)
clean_condo

clean_condo.head()

from google.colab import drive

clean_condo.to_csv('/drive/My Drive/Project_3/Oakland50_condo.csv')

import requests

url = "https://realtor.p.rapidapi.com/properties/v2/list-for-sale"

querystring = {"sort":"relevance","prop_type":"single_family","city":"Sacramento","limit":"200","offset":"0","state_code":"CA","radius":"20"}

headers = {
    'x-rapidapi-host': "realtor.p.rapidapi.com",
    'x-rapidapi-key': "520f14fa3cmshe49651674a1d7cfp1a9ee8jsne02bb6c7f697"
    }

response_single = requests.request("GET", url, headers=headers, params=querystring)
single_json = response_single.json()

single_properties = single_json['properties']

import pandas as pd
singlefam_listing=pd.DataFrame(single_properties)
len(singlefam_listing)

from pandas.io.json import json_normalize
singlefam_address = json_normalize(singlefam_listing['address'])
singlefam_address['county'].value_counts()

single_fam_df=pd.concat([singlefam_listing[['property_id', 'prop_type', 'price', 'baths_half', 'baths_full', 'beds', 'building_size','lot_size']],singlefam_address[['city', 'postal_code', 'state_code','county']]],axis=1)
single_fam_df.dropna(subset=['building_size','lot_size'], inplace=True)
single_fam_df

single_fam_df.fillna(0,inplace=True)
single_fam_df.reset_index(inplace=True)

single_fam_df

building_size = json_normalize(single_fam_df['building_size'])
lot_size=json_normalize(single_fam_df['lot_size'])
clean_single_df=pd.concat([single_fam_df,building_size['size']],axis=1)
clean_single_df.drop(columns='building_size',inplace=True)
clean_single_df.rename(columns={'size':'building_size'},inplace=True)
clean_single_df

singlefam_df=pd.concat([clean_single_df,lot_size['size']],axis=1)
singlefam_df.drop(columns='lot_size',inplace=True)
singlefam_df.rename(columns={'size':'lot_size'},inplace=True)

singlefam_df

from google.colab import drive

singlefam_df.to_csv('/drive/My Drive/Project_3/sacramento_single_family.csv')

#collecting all single_family
import pandas as pd
singlefam_sac = pd.read_csv('/drive/My Drive/Project_3/sacramento_single_family.csv')
singlefam_sf = pd.read_csv('/drive/My Drive/Project_3/sf_single_family.csv')
singlefam_oak = pd.read_csv('/drive/My Drive/Project_3/oakland_single_family.csv')
singlefam_sjose = pd.read_csv('/drive/My Drive/Project_3/sanjose_single_family.csv')

merge1 = pd.concat([singlefam_sac, singlefam_oak])
merge2 = pd.concat([singlefam_sf, singlefam_sjose])

del merge1['index']
merge1

merge2['building_size'].values

merge2.dropna(subset=['building_size'],inplace=True)

merge2

singlefam_nocal = pd.concat([merge1, merge2])
singlefam_nocal

singlefam_nocal.dropna(subset=['lot_size'],inplace=True)

singlefam_nocal.to_csv('/drive/My Drive/Project_3/northern_cali_singlefam.csv')

condo_sac = pd.read_csv('/drive/My Drive/Project_3/sacramento_condo.csv')
condo_sf = pd.read_csv('/drive/My Drive/Project_3/sanfrancsico_condo.csv')
condo_oak = pd.read_csv('/drive/My Drive/Project_3/Oakland50_condo.csv')
condo_sjose = pd.read_csv('/drive/My Drive/Project_3/sanjose_condo.csv')

merge3 = pd.concat([condo_sac, condo_oak])
merge4 = pd.concat([condo_sf, condo_sjose])

del merge3['Unnamed: 0']
del merge4['Unnamed: 0']

merge3['building_size'].values

merge4['building_size'].values

condo_nocal = pd.concat([merge3, merge4])
condo_nocal

condo_nocal.to_csv('/drive/My Drive/Project_3/northern_cali_condo.csv',index=False)

nocal_singlefam = pd.read_csv('/drive/My Drive/Project_3/northern_cali_singlefam.csv')
del nocal_singlefam ['Unnamed: 0']
nocal_singlefam
